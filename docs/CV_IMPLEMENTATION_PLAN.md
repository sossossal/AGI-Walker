# AGI-Walker è®¡ç®—æœºè§†è§‰ (CV) æ•°æ®ç”Ÿæˆå®ç°æ–¹æ¡ˆ

**æ—¥æœŸ**: 2026-01-18  
**ç‰ˆæœ¬**: 1.0  
**çŠ¶æ€**: å®æ–½æ–¹æ¡ˆ

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### å½“å‰çŠ¶æ€
- âœ… æ•°å€¼æ•°æ®ç”Ÿæˆ: 92% (å®Œæˆ)
- âš ï¸ è§†è§‰æ•°æ®ç”Ÿæˆ: 60% (éœ€è¦å®ç°)

### ç›®æ ‡
å®ç°å®Œæ•´çš„CVè®­ç»ƒæ•°æ®ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š
- RGBå›¾åƒ
- æ·±åº¦å›¾
- åˆ†å‰²æ©ç 
- å…³é”®ç‚¹æ ‡æ³¨
- è¾¹ç•Œæ¡†æ ‡æ³¨

### é¢„æœŸå®Œæˆåº¦
60% â†’ **95%**

---

## ğŸ¯ æ–¹æ¡ˆæ¦‚è§ˆ

### ä¸‰ç§å®ç°æ–¹æ¡ˆ

| æ–¹æ¡ˆ | å¤æ‚åº¦ | æ•ˆæœ | æ—¶é—´ | æ¨èåº¦ |
|------|-------|------|------|--------|
| æ–¹æ¡ˆ1: Godoté›†æˆ | é«˜ | ä¼˜ç§€ | 5-7å¤© | â­â­â­â­â­ |
| æ–¹æ¡ˆ2: PyBulleté›†æˆ | ä¸­ | è‰¯å¥½ | 3-4å¤© | â­â­â­â­ |
| æ–¹æ¡ˆ3: ç®€åŒ–æ¸²æŸ“ | ä½ | åŸºç¡€ | 1-2å¤© | â­â­â­ |

**æ¨è**: æ–¹æ¡ˆ1 (Godoté›†æˆ) - æœ€å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ

---

## æ–¹æ¡ˆ1: Godoté›†æˆ (æ¨è)

### æ¦‚è¿°
åˆ©ç”¨ç°æœ‰çš„Godoté¡¹ç›®ï¼Œé€šè¿‡Python-Godoté€šä¿¡ç”Ÿæˆè§†è§‰æ•°æ®

### æ¶æ„

```
Pythonæ§åˆ¶å™¨                 Godotæ¸²æŸ“å¼•æ“
    â”‚                           â”‚
    â”œâ”€> å‘é€æœºå™¨äººçŠ¶æ€ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚
    â”‚                           â”œâ”€> æ›´æ–°æœºå™¨äººå§¿æ€
    â”‚                           â”œâ”€> æ¸²æŸ“åœºæ™¯
    â”‚   <â”€â”€â”€â”€ è¿”å›å›¾åƒæ•°æ® <â”€â”€â”€â”€ â”œâ”€> æ•è·ç›¸æœºè§†å›¾
    â”‚                           â”œâ”€> ç”Ÿæˆæ·±åº¦å›¾
    â”‚                           â””â”€> è¯­ä¹‰åˆ†å‰²
    â”‚
    â””â”€> ä¿å­˜å›¾åƒ + æ ‡æ³¨
```

### å®ç°æ­¥éª¤

#### æ­¥éª¤1: Godotç«¯å®ç° (2-3å¤©)

**1.1 åˆ›å»ºç›¸æœºç³»ç»Ÿ**

```gdscript
# godot_project/scripts/VisionDataGenerator.gd
extends Node

var cameras = []
var capture_resolution = Vector2(640, 480)

func _ready():
    setup_cameras()

func setup_cameras():
    # ç¬¬ä¸‰äººç§°ç›¸æœº
    var third_person_cam = create_camera(
        Vector3(2, 1.5, 2),  # ä½ç½®
        Vector3(-30, -45, 0)  # æ—‹è½¬
    )
    cameras.append(third_person_cam)
    
    # ç¬¬ä¸€äººç§°ç›¸æœº (æœºå™¨äººè§†è§’)
    var first_person_cam = create_camera(
        Vector3(0, 0.3, 0.2),  # ç›¸å¯¹æœºå™¨äºº
        Vector3(0, 0, 0)
    )
    cameras.append(first_person_cam)
    
    # ä¿¯è§†ç›¸æœº
    var top_down_cam = create_camera(
        Vector3(0, 5, 0),
        Vector3(-90, 0, 0)
    )
    cameras.append(top_down_cam)

func create_camera(pos: Vector3, rot: Vector3) -> Camera:
    var camera = Camera.new()
    camera.transform.origin = pos
    camera.rotation_degrees = rot
    return camera

func capture_all_views() -> Dictionary:
    var images = {}
    
    for i in range(cameras.size()):
        var cam = cameras[i]
        
        # RGBå›¾åƒ
        images["rgb_" + str(i)] = capture_rgb(cam)
        
        # æ·±åº¦å›¾
        images["depth_" + str(i)] = capture_depth(cam)
        
        # åˆ†å‰²å›¾
        images["segmentation_" + str(i)] = capture_segmentation(cam)
    
    return images

func capture_rgb(camera: Camera) -> Image:
    var viewport = get_viewport()
    viewport.set_clear_mode(Viewport.CLEAR_MODE_ONLY_NEXT_FRAME)
    
    # æ¸²æŸ“ä¸€å¸§
    yield(get_tree(), "idle_frame")
    
    # æ•è·å›¾åƒ
    var image = viewport.get_texture().get_data()
    image.flip_y()
    
    return image

func capture_depth(camera: Camera) -> Image:
    # åˆ‡æ¢åˆ°æ·±åº¦æ¸²æŸ“æ¨¡å¼
    var shader = preload("res://shaders/depth_shader.shader")
    # ... å®ç°æ·±åº¦æ¸²æŸ“
    pass

func capture_segmentation(camera: Camera) -> Image:
    # è¯­ä¹‰åˆ†å‰²æ¸²æŸ“
    # æ¯ä¸ªå¯¹è±¡ç±»åˆ«ç”¨ä¸åŒé¢œè‰²
    pass
```

**1.2 åˆ›å»ºæ·±åº¦ç€è‰²å™¨**

```glsl
// godot_project/shaders/depth_shader.shader
shader_type spatial;

varying float depth;

void vertex() {
    vec4 world_pos = WORLD_MATRIX * vec4(VERTEX, 1.0);
    vec4 view_pos = VIEW_MATRIX * world_pos;
    depth = -view_pos.z;
}

void fragment() {
    # æ·±åº¦å½’ä¸€åŒ–åˆ°0-1
    float normalized_depth = depth / 10.0; # 10mæœ€å¤§æ·±åº¦
    ALBEDO = vec3(normalized_depth);
}
```

**1.3 TCPé€šä¿¡æœåŠ¡å™¨**

```gdscript
# godot_project/scripts/TCPVisionServer.gd
extends Node

var server = TCP_Server.new()
var connection = null
var port = 9999

func _ready():
    server.listen(port)
    print("Vision server listening on port ", port)

func _process(delta):
    # æ¥å—è¿æ¥
    if server.is_connection_available():
        connection = server.take_connection()
        print("Client connected")
    
    # å¤„ç†è¯·æ±‚
    if connection and connection.get_available_bytes() > 0:
        var request = connection.get_utf8_string(connection.get_available_bytes())
        handle_request(request)

func handle_request(request: String):
    var data = JSON.parse(request).result
    
    match data.command:
        "capture":
            var images = $VisionDataGenerator.capture_all_views()
            send_images(images)
        
        "update_robot":
            update_robot_state(data.state)
        
        "set_camera":
            set_camera_params(data.camera_id, data.params)

func send_images(images: Dictionary):
    var response = {
        "status": "success",
        "images": {}
    }
    
    for key in images:
        var image = images[key]
        # è½¬æ¢ä¸ºbase64æˆ–ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        response.images[key] = image_to_base64(image)
    
    connection.put_data(JSON.print(response).to_utf8())

func image_to_base64(image: Image) -> String:
    var buffer = image.save_png_to_buffer()
    return Marshalls.raw_to_base64(buffer)
```

#### æ­¥éª¤2: Pythonç«¯å®ç° (2-3å¤©)

**2.1 Godoté€šä¿¡å®¢æˆ·ç«¯**

```python
# python_api/godot_vision_client.py
"""
Godotè§†è§‰æ•°æ®é‡‡é›†å®¢æˆ·ç«¯
"""

import socket
import json
import base64
import numpy as np
from PIL import Image
import io
from typing import Dict, List, Optional


class GodotVisionClient:
    """Godotè§†è§‰æ•°æ®å®¢æˆ·ç«¯"""
    
    def __init__(self, host: str = 'localhost', port: int = 9999):
        self.host = host
        self.port = port
        self.socket = None
        self.connected = False
    
    def connect(self):
        """è¿æ¥åˆ°GodotæœåŠ¡å™¨"""
        try:
            self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.socket.connect((self.host, self.port))
            self.connected = True
            print(f"Connected to Godot server at {self.host}:{self.port}")
            return True
        except Exception as e:
            print(f"Failed to connect: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.socket:
            self.socket.close()
            self.connected = False
    
    def send_command(self, command: Dict) -> Dict:
        """å‘é€å‘½ä»¤å¹¶æ¥æ”¶å“åº”"""
        if not self.connected:
            raise ConnectionError("Not connected to Godot server")
        
        # å‘é€
        message = json.dumps(command).encode('utf-8')
        self.socket.sendall(message)
        
        # æ¥æ”¶
        response_data = b""
        while True:
            chunk = self.socket.recv(4096)
            if not chunk:
                break
            response_data += chunk
            
            # å°è¯•è§£æJSONï¼ˆç®€åŒ–ç‰ˆï¼‰
            try:
                response = json.loads(response_data.decode('utf-8'))
                return response
            except:
                continue
        
        return {}
    
    def update_robot_state(self, position: List[float], 
                          orientation: List[float],
                          joint_angles: List[float]):
        """æ›´æ–°æœºå™¨äººçŠ¶æ€"""
        command = {
            'command': 'update_robot',
            'state': {
                'position': position,
                'orientation': orientation,
                'joint_angles': joint_angles
            }
        }
        
        return self.send_command(command)
    
    def capture_images(self) -> Dict[str, np.ndarray]:
        """æ•è·æ‰€æœ‰è§†è§’çš„å›¾åƒ"""
        command = {'command': 'capture'}
        
        response = self.send_command(command)
        
        if response.get('status') != 'success':
            raise RuntimeError("Image capture failed")
        
        # è§£ç å›¾åƒ
        images = {}
        for key, base64_data in response['images'].items():
            image_bytes = base64.b64decode(base64_data)
            image = Image.open(io.BytesIO(image_bytes))
            images[key] = np.array(image)
        
        return images
    
    def set_camera_params(self, camera_id: int, fov: float = 70.0,
                         position: Optional[List[float]] = None):
        """è®¾ç½®ç›¸æœºå‚æ•°"""
        command = {
            'command': 'set_camera',
            'camera_id': camera_id,
            'params': {
                'fov': fov,
                'position': position or [0, 0, 0]
            }
        }
        
        return self.send_command(command)
```

**2.2 CVæ•°æ®ç”Ÿæˆå™¨**

```python
# python_api/cv_data_generator.py
"""
è®¡ç®—æœºè§†è§‰è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
"""

import numpy as np
import cv2
from pathlib import Path
from typing import Dict, List, Tuple
import json
from tqdm import tqdm

from python_api.godot_vision_client import GodotVisionClient
from python_api.data_recorder import DataRecorder


class CVDataGenerator:
    """CVè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "data/cv_dataset"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Godotå®¢æˆ·ç«¯
        self.godot_client = GodotVisionClient()
        
        # æ•°æ®ç»Ÿè®¡
        self.num_frames = 0
    
    def connect_to_godot(self) -> bool:
        """è¿æ¥åˆ°Godot"""
        return self.godot_client.connect()
    
    def generate_episode_images(self, episode_id: int, 
                               trajectory: List[Dict],
                               save_interval: int = 10):
        """
        ä¸ºä¸€ä¸ªepisodeç”Ÿæˆå›¾åƒ
        
        å‚æ•°:
            episode_id: Episode ID
            trajectory: è½¨è¿¹æ•°æ® (åŒ…å«æ¯æ­¥çš„çŠ¶æ€)
            save_interval: ä¿å­˜é—´éš”
        """
        episode_dir = self.output_dir / f"episode_{episode_id:06d}"
        episode_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (episode_dir / "rgb").mkdir(exist_ok=True)
        (episode_dir / "depth").mkdir(exist_ok=True)
        (episode_dir / "segmentation").mkdir(exist_ok=True)
        
        annotations = []
        
        for step_id, state in enumerate(tqdm(trajectory, desc=f"Episode {episode_id}")):
            if step_id % save_interval != 0:
                continue
            
            # æ›´æ–°Godotä¸­çš„æœºå™¨äººçŠ¶æ€
            self.godot_client.update_robot_state(
                position=state.get('position', [0, 0, 0]),
                orientation=state.get('orientation', [0, 0, 0]),
                joint_angles=state.get('joint_angles', [0]*6)
            )
            
            # æ•è·å›¾åƒ
            images = self.godot_client.capture_images()
            
            # ä¿å­˜å›¾åƒ
            for view_id, (key, image) in enumerate(images.items()):
                if 'rgb' in key:
                    filename = episode_dir / "rgb" / f"frame_{step_id:06d}_view_{view_id}.png"
                    cv2.imwrite(str(filename), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
                
                elif 'depth' in key:
                    filename = episode_dir / "depth" / f"frame_{step_id:06d}_view_{view_id}.png"
                    # æ·±åº¦å›¾ä¿å­˜ä¸º16ä½
                    depth_16bit = (image * 65535).astype(np.uint16)
                    cv2.imwrite(str(filename), depth_16bit)
                
                elif 'segmentation' in key:
                    filename = episode_dir / "segmentation" / f"frame_{step_id:06d}_view_{view_id}.png"
                    cv2.imwrite(str(filename), image)
            
            # ç”Ÿæˆæ ‡æ³¨
            annotation = self.generate_annotations(state, images)
            annotation['frame_id'] = step_id
            annotations.append(annotation)
            
            self.num_frames += 1
        
        # ä¿å­˜æ ‡æ³¨æ–‡ä»¶
        with open(episode_dir / "annotations.json", 'w') as f:
            json.dump(annotations, f, indent=2)
    
    def generate_annotations(self, state: Dict, images: Dict) -> Dict:
        """
        ç”Ÿæˆæ ‡æ³¨ä¿¡æ¯
        
        åŒ…æ‹¬:
        - æœºå™¨äººå§¿æ€
        - å…³é”®ç‚¹ä½ç½®
        - è¾¹ç•Œæ¡†
        - è¯­ä¹‰æ ‡ç­¾
        """
        annotation = {
            'robot_state': state,
            'keypoints': self.detect_keypoints(images),
            'bounding_boxes': self.detect_bounding_boxes(images),
            'semantic_labels': self.extract_semantic_labels(images)
        }
        
        return annotation
    
    def detect_keypoints(self, images: Dict) -> List[Dict]:
        """æ£€æµ‹å…³é”®ç‚¹ï¼ˆå…³èŠ‚ä½ç½®ï¼‰"""
        # è¿™é‡Œåº”è¯¥ä»Godotè·å–3Då…³èŠ‚ä½ç½®
        # å¹¶æŠ•å½±åˆ°2Då›¾åƒå¹³é¢
        keypoints = [
            {'name': 'hip', 'position_2d': [320, 240, 1.0]},  # [x, y, visibility]
            {'name': 'knee', 'position_2d': [340, 300, 1.0]},
            # ... æ›´å¤šå…³èŠ‚
        ]
        return keypoints
    
    def detect_bounding_boxes(self, images: Dict) -> List[Dict]:
        """æ£€æµ‹è¾¹ç•Œæ¡†"""
        # æœºå™¨äººçš„è¾¹ç•Œæ¡†
        boxes = [
            {
                'class': 'robot',
                'bbox': [100, 150, 500, 400],  # [x, y, w, h]
                'confidence': 1.0
            }
        ]
        return boxes
    
    def extract_semantic_labels(self, images: Dict) -> Dict:
        """æå–è¯­ä¹‰æ ‡ç­¾"""
        # ä»åˆ†å‰²å›¾ä¸­æå–
        labels = {
            'robot': 1,
            'ground': 2,
            'obstacle': 3,
            'background': 0
        }
        return labels
    
    def batch_generate(self, num_episodes: int, 
                      episode_length: int = 100,
                      save_interval: int = 5):
        """
        æ‰¹é‡ç”ŸæˆCVæ•°æ®é›†
        
        å‚æ•°:
            num_episodes: Episodeæ•°é‡
            episode_length: æ¯ä¸ªepisodeçš„é•¿åº¦
            save_interval: å›¾åƒä¿å­˜é—´éš”
        """
        if not self.connect_to_godot():
            print("Failed to connect to Godot. Make sure Godot is running.")
            return
        
        print(f"Generating CV dataset: {num_episodes} episodes")
        
        for ep_id in range(num_episodes):
            # è¿™é‡Œåº”è¯¥è¿è¡Œä»¿çœŸè·å–è½¨è¿¹
            # ç®€åŒ–ç¤ºä¾‹ï¼šä½¿ç”¨éšæœºè½¨è¿¹
            trajectory = self.generate_random_trajectory(episode_length)
            
            # ç”Ÿæˆå›¾åƒ
            self.generate_episode_images(ep_id, trajectory, save_interval)
        
        print(f"\nGeneration complete!")
        print(f"Total frames: {self.num_frames}")
        print(f"Output directory: {self.output_dir}")
    
    def generate_random_trajectory(self, length: int) -> List[Dict]:
        """ç”Ÿæˆéšæœºè½¨è¿¹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        trajectory = []
        
        for i in range(length):
            state = {
                'position': [i * 0.01, 0, 0],  # å‰è¿›
                'orientation': [0, 0, 0],
                'joint_angles': [0] * 6
            }
            trajectory.append(state)
        
        return trajectory
```

#### æ­¥éª¤3: æ•°æ®é›†æ ¼å¼ (1å¤©)

**COCOæ ¼å¼æ”¯æŒ**

```python
# python_api/cv_dataset_converter.py
"""
è½¬æ¢CVæ•°æ®é›†ä¸ºæ ‡å‡†æ ¼å¼
"""

import json
from pathlib import Path


class COCOConverter:
    """è½¬æ¢ä¸ºCOCOæ ¼å¼"""
    
    def __init__(self, dataset_dir: str):
        self.dataset_dir = Path(dataset_dir)
    
    def convert(self, output_file: str):
        """è½¬æ¢æ•´ä¸ªæ•°æ®é›†"""
        coco_data = {
            'images': [],
            'annotations': [],
            'categories': [
                {'id': 1, 'name': 'robot'},
                {'id': 2, 'name': 'ground'},
                {'id': 3, 'name': 'obstacle'}
            ]
        }
        
        annotation_id = 0
        
        # éå†æ‰€æœ‰episodes
        for episode_dir in self.dataset_dir.glob("episode_*"):
            annotations_file = episode_dir / "annotations.json"
            
            if not annotations_file.exists():
                continue
            
            with open(annotations_file, 'r') as f:
                annotations = json.load(f)
            
            for ann in annotations:
                frame_id = ann['frame_id']
                
                # æ·»åŠ å›¾åƒä¿¡æ¯
                image_info = {
                    'id': len(coco_data['images']),
                    'file_name': f"{episode_dir.name}/rgb/frame_{frame_id:06d}_view_0.png",
                    'width': 640,
                    'height': 480
                }
                coco_data['images'].append(image_info)
                
                # æ·»åŠ æ ‡æ³¨
                for bbox in ann['bounding_boxes']:
                    coco_ann = {
                        'id': annotation_id,
                        'image_id': image_info['id'],
                        'category_id': 1,  # robot
                        'bbox': bbox['bbox'],
                        'area': bbox['bbox'][2] * bbox['bbox'][3],
                        'iscrowd': 0
                    }
                    coco_data['annotations'].append(coco_ann)
                    annotation_id += 1
                
                # æ·»åŠ å…³é”®ç‚¹
                for kp in ann['keypoints']:
                    coco_kp = {
                        'id': annotation_id,
                        'image_id': image_info['id'],
                        'category_id': 1,
                        'keypoints': kp['position_2d'] * 6,  # COCOæ ¼å¼
                        'num_keypoints': 6
                    }
                    coco_data['annotations'].append(coco_kp)
                    annotation_id += 1
        
        # ä¿å­˜
        with open(output_file, 'w') as f:
            json.dump(coco_data, f, indent=2)
        
        print(f"COCO dataset saved to: {output_file}")
```

---

## æ–¹æ¡ˆ2: PyBulleté›†æˆ (å¤‡é€‰)

### æ¦‚è¿°
ä½¿ç”¨PyBulletçš„æ¸²æŸ“åŠŸèƒ½ç”Ÿæˆå›¾åƒ

### ä¼˜åŠ¿
- å®Œå…¨Pythonå®ç°
- æ›´å®¹æ˜“é›†æˆ
- ä¸éœ€è¦Godotè¿è¡Œ

---

## æ–¹æ¡ˆ3: ç®€åŒ–æ¸²æŸ“ (å¿«é€Ÿæ–¹æ¡ˆ)

### æ¦‚è¿°
ä½¿ç”¨matplotlibæˆ–pygameè¿›è¡Œ2Dæ¸²æŸ“

### é€‚ç”¨åœºæ™¯
- å¿«é€ŸåŸå‹
- ä¸éœ€è¦çœŸå®æ„Ÿ
- 2Dä»»åŠ¡

---

## ğŸ“Š å¯¹æ¯”æ€»ç»“

| ç‰¹æ€§ | Godot | PyBullet | ç®€åŒ–æ¸²æŸ“ |
|------|-------|----------|----------|
| å›¾åƒè´¨é‡ | â­â­â­â­â­ | â­â­â­â­ | â­â­ |
| å®ç°éš¾åº¦ | é«˜ | ä¸­ | ä½ |
| å¼€å‘æ—¶é—´ | 5-7å¤© | 3-4å¤© | 1-2å¤© |
| æ¨èåº¦ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |

---

## ğŸ¯ æ¨èå®æ–½è·¯çº¿

### Phase 1: åŸºç¡€å®ç° (3-4å¤©)
1. Godot TCPæœåŠ¡å™¨
2. Pythonå®¢æˆ·ç«¯
3. åŸºç¡€å›¾åƒæ•è·

### Phase 2: å¢å¼ºåŠŸèƒ½ (2-3å¤©)
4. æ·±åº¦å›¾æ¸²æŸ“
5. è¯­ä¹‰åˆ†å‰²
6. å¤šç›¸æœºè§†è§’

### Phase 3: é›†æˆä¼˜åŒ– (1-2å¤©)
7. æ‰¹é‡ç”Ÿæˆé›†æˆ
8. æ•°æ®é›†æ ¼å¼è½¬æ¢
9. æ€§èƒ½ä¼˜åŒ–

**æ€»æ—¶é—´**: 6-9å¤©

---

## âœ… å®æ–½åæ•ˆæœ

**æ•°æ®ç±»å‹**:
- RGBå›¾åƒ (640x480 æˆ–æ›´é«˜)
- æ·±åº¦å›¾ (16-bit)
- è¯­ä¹‰åˆ†å‰²å›¾
- å…³é”®ç‚¹æ ‡æ³¨
- è¾¹ç•Œæ¡†æ ‡æ³¨
