"""
å¥–åŠ±å‡½æ•°è®¾è®¡å·¥å…·
å¯é…ç½®ã€å¯ç»„åˆçš„å¥–åŠ±å‡½æ•°ç³»ç»Ÿ
"""

import numpy as np
from typing import Dict, List, Optional, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum


class RewardComponent(Enum):
    """å¥–åŠ±ç»„ä»¶ç±»å‹"""
    FORWARD_VELOCITY = "forward_velocity"
    STABILITY = "stability"
    ENERGY_EFFICIENCY = "energy_efficiency"
    SURVIVAL = "survival"
    HEIGHT_MAINTENANCE = "height_maintenance"
    SMOOTH_MOTION = "smooth_motion"
    SYMMETRY = "symmetry"
    TARGET_TRACKING = "target_tracking"


@dataclass
class RewardConfig:
    """å¥–åŠ±é…ç½®"""
    # ç»„ä»¶æƒé‡
    weights: Dict[str, float] = field(default_factory=lambda: {
        "forward_velocity": 1.0,
        "stability": 0.5,
        "energy_efficiency": 0.3,
        "survival": 0.2,
        "height_maintenance": 0.4,
        "smooth_motion": 0.2,
        "symmetry": 0.1
    })
    
    # é˜ˆå€¼å‚æ•°
    max_roll: float = 30.0          # æœ€å¤§Rollè§’åº¦
    max_pitch: float = 30.0         # æœ€å¤§Pitchè§’åº¦
    target_height: float = 1.45     # ç›®æ ‡é«˜åº¦
    height_tolerance: float = 0.2   # é«˜åº¦å®¹å·®
    
    # æƒ©ç½šå‚æ•°
    fall_penalty: float = -10.0     # è·Œå€’æƒ©ç½š
    energy_scale: float = 0.01      # èƒ½é‡æ¶ˆè€—ç¼©æ”¾


class RewardDesigner:
    """
    å¥–åŠ±å‡½æ•°è®¾è®¡å™¨
    
    åŠŸèƒ½ï¼š
    1. å¯é…ç½®çš„å¥–åŠ±ç»„ä»¶
    2. è‡ªåŠ¨æƒé‡è°ƒæ•´
    3. å¥–åŠ±åˆ†è§£å’Œå¯è§†åŒ–
    """
    
    def __init__(self, config: Optional[RewardConfig] = None):
        self.config = config or RewardConfig()
        
        # å†å²è®°å½•ï¼ˆç”¨äºå¹³æ»‘å’Œç»Ÿè®¡ï¼‰
        self.prev_action: Optional[np.ndarray] = None
        self.prev_velocity: float = 0.0
        self.episode_rewards: List[float] = []
        self.component_history: Dict[str, List[float]] = {}
        
        # ç»Ÿè®¡
        self.total_calls = 0
    
    def compute_reward(
        self,
        obs: dict,
        action: np.ndarray,
        info: Optional[dict] = None
    ) -> Tuple[float, dict]:
        """
        è®¡ç®—ç»„åˆå¥–åŠ±
        
        Args:
            obs: è§‚æµ‹æ•°æ®
            action: æ‰§è¡Œçš„åŠ¨ä½œ
            info: é¢å¤–ä¿¡æ¯
        
        Returns:
            (æ€»å¥–åŠ±, åˆ†è§£è¯¦æƒ…)
        """
        self.total_calls += 1
        
        # æå–çŠ¶æ€
        sensors = obs.get('sensors', {})
        imu = sensors.get('imu', {})
        orient = imu.get('orient', [0, 0, 0])
        height = obs.get('torso_height', 1.45)
        
        roll, pitch = orient[0], orient[1]
        
        # è®¡ç®—å„ç»„ä»¶
        components = {}
        
        # 1. å‰è¿›é€Ÿåº¦å¥–åŠ±
        if 'forward_velocity' in self.config.weights:
            velocity = info.get('forward_velocity', 0) if info else 0
            velocity_reward = self._compute_velocity_reward(velocity)
            components['forward_velocity'] = velocity_reward
        
        # 2. ç¨³å®šæ€§å¥–åŠ±
        if 'stability' in self.config.weights:
            stability_reward = self._compute_stability_reward(roll, pitch)
            components['stability'] = stability_reward
        
        # 3. èƒ½é‡æ•ˆç‡å¥–åŠ±
        if 'energy_efficiency' in self.config.weights:
            energy_reward = self._compute_energy_reward(action)
            components['energy_efficiency'] = energy_reward
        
        # 4. å­˜æ´»å¥–åŠ±
        if 'survival' in self.config.weights:
            survival_reward = 1.0  # æ¯æ­¥å­˜æ´»+1
            components['survival'] = survival_reward
        
        # 5. é«˜åº¦ç»´æŒå¥–åŠ±
        if 'height_maintenance' in self.config.weights:
            height_reward = self._compute_height_reward(height)
            components['height_maintenance'] = height_reward
        
        # 6. åŠ¨ä½œå¹³æ»‘å¥–åŠ±
        if 'smooth_motion' in self.config.weights:
            smooth_reward = self._compute_smooth_reward(action)
            components['smooth_motion'] = smooth_reward
        
        # 7. å¯¹ç§°æ€§å¥–åŠ±
        if 'symmetry' in self.config.weights:
            symmetry_reward = self._compute_symmetry_reward(obs)
            components['symmetry'] = symmetry_reward
        
        # åŠ æƒæ±‚å’Œ
        total_reward = 0.0
        for comp_name, comp_value in components.items():
            weight = self.config.weights.get(comp_name, 0.0)
            total_reward += weight * comp_value
        
        # æ£€æŸ¥è·Œå€’
        if self._check_fall(roll, pitch, height):
            total_reward += self.config.fall_penalty
            components['fall_penalty'] = self.config.fall_penalty
        
        # æ›´æ–°å†å²
        self.prev_action = action.copy()
        self.episode_rewards.append(total_reward)
        
        for comp_name, comp_value in components.items():
            if comp_name not in self.component_history:
                self.component_history[comp_name] = []
            self.component_history[comp_name].append(comp_value)
        
        return total_reward, components
    
    def _compute_velocity_reward(self, velocity: float) -> float:
        """å‰è¿›é€Ÿåº¦å¥–åŠ±"""
        # æœŸæœ›é€Ÿåº¦èŒƒå›´: 0.5 - 1.0 m/s
        if velocity > 0:
            return min(velocity, 1.0)  # ä¸Šé™1.0
        else:
            return velocity * 0.5  # åé€€æƒ©ç½š
    
    def _compute_stability_reward(self, roll: float, pitch: float) -> float:
        """ç¨³å®šæ€§å¥–åŠ±"""
        # å§¿æ€è¶Šæ¥è¿‘0ï¼Œå¥–åŠ±è¶Šé«˜
        roll_penalty = (roll / self.config.max_roll) ** 2
        pitch_penalty = (pitch / self.config.max_pitch) ** 2
        
        stability = 1.0 - min(1.0, roll_penalty + pitch_penalty)
        return stability
    
    def _compute_energy_reward(self, action: np.ndarray) -> float:
        """èƒ½é‡æ•ˆç‡å¥–åŠ±ï¼ˆæƒ©ç½šå¤§åŠ¨ä½œï¼‰"""
        action_magnitude = np.sum(action ** 2)
        energy_cost = action_magnitude * self.config.energy_scale
        return -energy_cost
    
    def _compute_height_reward(self, height: float) -> float:
        """é«˜åº¦ç»´æŒå¥–åŠ±"""
        height_error = abs(height - self.config.target_height)
        
        if height_error < self.config.height_tolerance:
            return 1.0
        else:
            return max(0.0, 1.0 - height_error / self.config.target_height)
    
    def _compute_smooth_reward(self, action: np.ndarray) -> float:
        """åŠ¨ä½œå¹³æ»‘å¥–åŠ±"""
        if self.prev_action is None:
            return 0.0
        
        action_diff = np.sum((action - self.prev_action) ** 2)
        smoothness = 1.0 - min(1.0, action_diff * 0.1)
        return smoothness
    
    def _compute_symmetry_reward(self, obs: dict) -> float:
        """å¯¹ç§°æ€§å¥–åŠ±"""
        joints = obs.get('sensors', {}).get('joints', {})
        
        hip_left = joints.get('hip_left', {}).get('angle', 0)
        hip_right = joints.get('hip_right', {}).get('angle', 0)
        
        # ç†æƒ³æƒ…å†µä¸‹å·¦å³å¯¹ç§°
        asymmetry = abs(hip_left + hip_right) / 90.0  # å½’ä¸€åŒ–
        symmetry = 1.0 - min(1.0, asymmetry)
        
        return symmetry
    
    def _check_fall(self, roll: float, pitch: float, height: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦è·Œå€’"""
        return (
            abs(roll) > 45 or
            abs(pitch) > 45 or
            height < 0.3
        )
    
    def reset(self):
        """é‡ç½®episodeçŠ¶æ€"""
        self.prev_action = None
        self.prev_velocity = 0.0
        self.episode_rewards.clear()
        self.component_history.clear()
    
    def set_weight(self, component: str, weight: float):
        """è®¾ç½®ç»„ä»¶æƒé‡"""
        if component in self.config.weights:
            self.config.weights[component] = weight
            print(f"è®¾ç½® {component} æƒé‡ä¸º {weight}")
        else:
            print(f"âš ï¸ æœªçŸ¥ç»„ä»¶: {component}")
    
    def auto_tune(self, demonstrations: List[dict], target_metric: str = "survival_time"):
        """
        ä»æ¼”ç¤ºæ•°æ®è‡ªåŠ¨è°ƒæ•´æƒé‡
        
        Args:
            demonstrations: æ¼”ç¤ºè½¨è¿¹åˆ—è¡¨
            target_metric: ç›®æ ‡æŒ‡æ ‡
        """
        print(f"ğŸ”§ å¼€å§‹è‡ªåŠ¨è°ƒæ•´æƒé‡...")
        print(f"   æ¼”ç¤ºæ•°æ®: {len(demonstrations)}æ¡")
        print(f"   ç›®æ ‡æŒ‡æ ‡: {target_metric}")
        
        # åˆ†ææ¼”ç¤ºæ•°æ®
        success_demos = [d for d in demonstrations if d.get('success', False)]
        fail_demos = [d for d in demonstrations if not d.get('success', False)]
        
        if not success_demos:
            print("âš ï¸ æ²¡æœ‰æˆåŠŸæ¼”ç¤ºï¼Œæ— æ³•è°ƒæ•´")
            return
        
        # è®¡ç®—æˆåŠŸæ¼”ç¤ºçš„å¹³å‡ç‰¹å¾
        success_features = self._extract_features(success_demos)
        fail_features = self._extract_features(fail_demos) if fail_demos else {}
        
        # è°ƒæ•´æƒé‡
        for comp_name in self.config.weights:
            success_value = success_features.get(comp_name, 0.5)
            fail_value = fail_features.get(comp_name, 0.5)
            
            # å¦‚æœæˆåŠŸæ¼”ç¤ºä¸­è¯¥ç»„ä»¶å€¼æ›´é«˜ï¼Œå¢åŠ æƒé‡
            if success_value > fail_value:
                factor = 1.2
            else:
                factor = 0.8
            
            self.config.weights[comp_name] *= factor
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.config.weights.values())
        for comp_name in self.config.weights:
            self.config.weights[comp_name] /= total_weight
        
        print("âœ… æƒé‡è°ƒæ•´å®Œæˆ")
        print(f"   æ–°æƒé‡: {self.config.weights}")
    
    def _extract_features(self, demonstrations: List[dict]) -> dict:
        """ä»æ¼”ç¤ºä¸­æå–ç‰¹å¾"""
        features = {}
        
        for demo in demonstrations:
            for comp_name, values in demo.get('components', {}).items():
                if comp_name not in features:
                    features[comp_name] = []
                features[comp_name].extend(values)
        
        # è®¡ç®—å¹³å‡å€¼
        for comp_name in features:
            features[comp_name] = np.mean(features[comp_name]) if features[comp_name] else 0.0
        
        return features
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_calls": self.total_calls,
            "weights": self.config.weights,
            "episode_reward_mean": np.mean(self.episode_rewards) if self.episode_rewards else 0,
            "episode_reward_std": np.std(self.episode_rewards) if self.episode_rewards else 0,
            "component_means": {
                name: np.mean(values) if values else 0
                for name, values in self.component_history.items()
            }
        }


def create_reward_designer(
    preset: str = "balanced"
) -> RewardDesigner:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå¥–åŠ±è®¾è®¡å™¨
    
    presets:
    - "balanced": å¹³è¡¡é…ç½®
    - "speed": é€Ÿåº¦ä¼˜å…ˆ
    - "stability": ç¨³å®šæ€§ä¼˜å…ˆ
    - "efficiency": èƒ½é‡æ•ˆç‡ä¼˜å…ˆ
    """
    presets = {
        "balanced": RewardConfig(),
        "speed": RewardConfig(weights={
            "forward_velocity": 2.0,
            "stability": 0.3,
            "energy_efficiency": 0.1,
            "survival": 0.2,
            "height_maintenance": 0.3,
            "smooth_motion": 0.1,
            "symmetry": 0.0
        }),
        "stability": RewardConfig(weights={
            "forward_velocity": 0.3,
            "stability": 2.0,
            "energy_efficiency": 0.2,
            "survival": 0.5,
            "height_maintenance": 0.8,
            "smooth_motion": 0.3,
            "symmetry": 0.2
        }),
        "efficiency": RewardConfig(weights={
            "forward_velocity": 0.5,
            "stability": 0.4,
            "energy_efficiency": 2.0,
            "survival": 0.2,
            "height_maintenance": 0.3,
            "smooth_motion": 0.5,
            "symmetry": 0.1
        })
    }
    
    config = presets.get(preset, presets["balanced"])
    return RewardDesigner(config)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import json
    
    print("å¥–åŠ±å‡½æ•°è®¾è®¡å™¨æµ‹è¯•\n")
    
    # åˆ›å»ºè®¾è®¡å™¨
    designer = create_reward_designer("balanced")
    
    # æ¨¡æ‹Ÿè§‚æµ‹
    obs = {
        "sensors": {
            "imu": {"orient": [5.0, -3.0, 0.0]},
            "joints": {
                "hip_left": {"angle": 10.0},
                "hip_right": {"angle": -8.0}
            }
        },
        "torso_height": 1.40
    }
    
    action = np.array([0.5, -0.3])
    info = {"forward_velocity": 0.3}
    
    # è®¡ç®—å¥–åŠ±
    print("=== æ­£å¸¸çŠ¶æ€ ===")
    reward, components = designer.compute_reward(obs, action, info)
    print(f"æ€»å¥–åŠ±: {reward:.3f}")
    print(f"ç»„ä»¶åˆ†è§£: {json.dumps(components, indent=2)}")
    
    # ä¸ç¨³å®šçŠ¶æ€
    print("\n=== ä¸ç¨³å®šçŠ¶æ€ ===")
    unstable_obs = {
        "sensors": {
            "imu": {"orient": [25.0, -20.0, 0.0]},
            "joints": {
                "hip_left": {"angle": 30.0},
                "hip_right": {"angle": -5.0}
            }
        },
        "torso_height": 1.2
    }
    
    reward, components = designer.compute_reward(unstable_obs, action, info)
    print(f"æ€»å¥–åŠ±: {reward:.3f}")
    
    # è·Œå€’çŠ¶æ€
    print("\n=== è·Œå€’çŠ¶æ€ ===")
    fall_obs = {
        "sensors": {
            "imu": {"orient": [50.0, -40.0, 0.0]},
            "joints": {"hip_left": {"angle": 0}, "hip_right": {"angle": 0}}
        },
        "torso_height": 0.2
    }
    
    reward, components = designer.compute_reward(fall_obs, action, info)
    print(f"æ€»å¥–åŠ±: {reward:.3f}")
    print(f"åŒ…å«è·Œå€’æƒ©ç½š: {components.get('fall_penalty', 0)}")
    
    # ç»Ÿè®¡
    print("\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
    print(json.dumps(designer.get_stats(), indent=2))
