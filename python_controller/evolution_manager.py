"""
è¿›åŒ–å¾ªç¯ç®¡ç†å™¨
ä¸²è”RLè®­ç»ƒã€æ•°æ®ç”Ÿæˆã€è‡ªåŠ¨æ ‡è®°å’ŒPEFTå¾®è°ƒï¼Œå®ç°è‡ªåŠ¨åŒ–è¿›åŒ–
"""

import os
import time
import json
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass

import sys
sys.path.append(str(Path(__file__).parent.parent))

# å¯¼å…¥å„æ¨¡å—
try:
    from python_controller.rl_optimizer import RLOptimizer, RLConfig, DummyEnv
except ImportError:
    from rl_optimizer import RLOptimizer, RLConfig, DummyEnv

from training.auto_labeler import AutoLabeler
from training.dataset_cleaner import DatasetCleaner
from training.peft_trainer import PEFTTrainer, PEFTConfig, PEFTMethod


@dataclass
class EvolutionConfig:
    """è¿›åŒ–å¾ªç¯é…ç½®"""
    # è·¯å¾„é…ç½®
    workspace_dir: str = "d:/æ–°å»ºæ–‡ä»¶å¤¹/AGI-Walker"
    iteration_name: str = "evo_v1"
    
    # RLé…ç½®
    rl_timesteps: int = 50000
    rl_algorithm: str = "PPO"
    
    # æ•°æ®ç”Ÿæˆ
    n_trajectories: int = 100
    
    # å¾®è°ƒé…ç½®
    peft_method: str = "prefix_tuning"
    peft_epochs: int = 3
    
    # è‡ªåŠ¨åŒ–
    auto_proceed: bool = True


class EvolutionManager:
    """
    è¿›åŒ–å¾ªç¯ç®¡ç†å™¨
    
    å®ç°å®Œæ•´çš„è‡ªåŠ¨åŒ–è¿›åŒ–æµç¨‹ï¼š
    1. RLæ¢ç´¢ä¸è®­ç»ƒ (Stage 4)
    2. ç­–ç•¥éƒ¨ç½²ä¸æ•°æ®ç”Ÿæˆ
    3. æ•°æ®è‡ªåŠ¨æ ‡è®°ä¸æ¸…æ´— (Stage 5)
    4. å°æ¨¡å‹PEFTå¾®è°ƒ
    5. æ¨¡å‹è¯„ä¼°ä¸éƒ¨ç½²
    """
    
    def __init__(self, config: Optional[EvolutionConfig] = None):
        self.config = config or EvolutionConfig()
        
        # ç›®å½•è®¾ç½®
        self.workspace = Path(self.config.workspace_dir)
        self.data_dir = self.workspace / "offline_data" / self.config.iteration_name
        self.models_dir = self.workspace / "models" / self.config.iteration_name
        
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # çŠ¶æ€
        self.current_stage = "INIT"
        self.history = []
        
        print(f"âœ… è¿›åŒ–ç®¡ç†å™¨åˆå§‹åŒ–: {self.config.iteration_name}")
    
    async def run_loop(self):
        """è¿è¡Œå®Œæ•´è¿›åŒ–å¾ªç¯"""
        print("=" * 50)
        print(f"ğŸš€ å¼€å§‹è¿›åŒ–å¾ªç¯: {self.config.iteration_name}")
        print("=" * 50)
        
        start_time = time.time()
        
        # 1. RL è®­ç»ƒ
        rl_model_path = await self.stage_rl_training()
        
        # 2. æ•°æ®ç”Ÿæˆ
        raw_data_path = await self.stage_data_generation(rl_model_path)
        
        # 3. æ•°æ®æ ‡è®°ä¸æ¸…æ´—
        clean_data_path = await self.stage_data_processing(raw_data_path)
        
        # 4. PEFT å¾®è°ƒ
        final_model_path = await self.stage_model_finetuning(clean_data_path)
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ è¿›åŒ–å¾ªç¯å®Œæˆ! ç”¨æ—¶: {total_time:.1f}ç§’")
        print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {final_model_path}")
        
        return final_model_path
    
    async def stage_rl_training(self) -> str:
        """é˜¶æ®µ1: RLè®­ç»ƒ"""
        self.current_stage = "RL_TRAINING"
        print(f"\n[Stage 1/4] RLè®­ç»ƒ ({self.config.rl_algorithm})")
        
        # é…ç½®RL
        rl_config = RLConfig(
            algorithm=self.config.rl_algorithm,
            tensorboard_log=str(self.models_dir / "tensorboard")
        )
        
        # åˆ›å»ºä¼˜åŒ–å™¨ (ä½¿ç”¨DummyEnvæ¨¡æ‹Ÿï¼Œå®é™…åº”è¿æ¥Godot)
        # å®é™…ä»£ç : from gym_env import GodotRobotEnv; env = GodotRobotEnv()
        env = DummyEnv() 
        optimizer = RLOptimizer(env, rl_config, save_dir=str(self.models_dir / "rl"))
        
        # è®­ç»ƒï¼ˆä½¿ç”¨çº¿ç¨‹æ± æˆ–å¼‚æ­¥æ‰§è¡Œï¼‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None, 
            lambda: optimizer.train(total_timesteps=self.config.rl_timesteps)
        )
        
        # å¯¼å‡ºæ¨¡å‹
        model_path = self.models_dir / "rl" / f"{self.config.rl_algorithm.lower()}_final.zip"
        
        # åŒæ—¶å¯¼å‡ºONNX
        onnx_path = self.models_dir / "rl" / "policy.onnx"
        optimizer.export_policy_onnx(str(onnx_path))
        
        self.history.append({"stage": "rl", "status": "success", "path": str(model_path)})
        return str(model_path)
    
    async def stage_data_generation(self, model_path: str) -> str:
        """é˜¶æ®µ2: æ•°æ®ç”Ÿæˆ"""
        self.current_stage = "DATA_GEN"
        print(f"\n[Stage 2/4] æ•°æ®ç”Ÿæˆ ({self.config.n_trajectories} trajectories)")
        
        output_path = self.data_dir / "raw_trajectories.json"
        
        # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆè¿‡ç¨‹
        # è¿™é‡Œåº”è¯¥åŠ è½½RLæ¨¡å‹å¹¶åœ¨ç¯å¢ƒä¸­è¿è¡Œï¼Œæ”¶é›†æ•°æ®
        print("   æ­£åœ¨è¿è¡Œç­–ç•¥æ”¶é›†æ•°æ®...")
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿè€—æ—¶
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        import random
        trajectories = []
        for i in range(self.config.n_trajectories):
            traj = {
                "id": f"traj_{i}",
                "states": [{"sensors": {"imu": {"orient": [random.uniform(-5, 5), random.uniform(-5, 5), 0]}}} for _ in range(50)],
                "actions": [[random.random(), random.random()] for _ in range(50)],
                "avg_velocity": random.uniform(0, 1.0),
                "terminated": random.random() < 0.2
            }
            trajectories.append(traj)
            
        with open(output_path, 'w') as f:
            json.dump(trajectories, f)
            
        print(f"âœ… æ•°æ®å·²ä¿å­˜: {output_path}")
        self.history.append({"stage": "data_gen", "status": "success", "count": len(trajectories)})
        return str(output_path)
    
    async def stage_data_processing(self, input_path: str) -> str:
        """é˜¶æ®µ3: æ•°æ®æ ‡è®°ä¸æ¸…æ´—"""
        self.current_stage = "DATA_PROC"
        print(f"\n[Stage 3/4] æ•°æ®å¤„ç†")
        
        # 1. è‡ªåŠ¨æ ‡è®°
        labeler = AutoLabeler()
        labeled_path = self.data_dir / "labeled_data.json"
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: labeler.batch_label(input_path, str(labeled_path))
        )
        
        # 2. æ¸…æ´—
        cleaner = DatasetCleaner()
        
        with open(labeled_path, 'r', encoding='utf-8') as f:
            labeled_data = json.load(f)
            
        cleaned_data = cleaner.clean_pipeline(
            labeled_data,
            balance=True
        )
        
        clean_path = self.data_dir / "train_data.json"
        cleaner.save_dataset(cleaned_data, str(clean_path))
        
        self.history.append({"stage": "processing", "status": "success", "final_count": len(cleaned_data)})
        return str(clean_path)
    
    async def stage_model_finetuning(self, dataset_path: str) -> str:
        """é˜¶æ®µ4: PEFTå¾®è°ƒ"""
        self.current_stage = "FINETUNING"
        print(f"\n[Stage 4/4] PEFTå¾®è°ƒ ({self.config.peft_method})")
        
        peft_config = PEFTConfig(
            method=PEFTMethod(self.config.peft_method),
            num_epochs=self.config.peft_epochs
        )
        
        trainer = PEFTTrainer(
            config=peft_config,
            output_dir=str(self.models_dir / "peft")
        )
        
        # æ¨¡æ‹Ÿè®­ç»ƒï¼ˆå› ä¸ºæ²¡æœ‰å®‰è£…transformers/datasetsåº“ï¼‰
        # å®é™…ä»£ç :
        # dataset = trainer.prepare_dataset(dataset_path)
        # trainer.train(dataset)
        
        print("   å¾®è°ƒä¸­...")
        await asyncio.sleep(2) # æ¨¡æ‹Ÿ
        
        # æ¨¡æ‹Ÿä¿å­˜
        final_path = self.models_dir / "peft" / "final"
        final_path.mkdir(parents=True, exist_ok=True)
        with open(final_path / "model_info.json", 'w') as f:
            json.dump(trainer.get_stats(), f)
            
        print(f"âœ… å¾®è°ƒå®Œæˆ: {final_path}")
        self.history.append({"stage": "finetuning", "status": "success"})
        return str(final_path)
    
    def get_report(self) -> str:
        """ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š"""
        report = f"# è¿›åŒ–æŠ¥å‘Š: {self.config.iteration_name}\n\n"
        
        for item in self.history:
            status_icon = "âœ…" if item['status'] == 'success' else "âŒ"
            report += f"## {status_icon} Stage: {item['stage']}\n"
            report += f"{json.dumps(item, indent=2)}\n\n"
            
        return report


# æµ‹è¯•ä»£ç 
async def test_evolution():
    print("è¿›åŒ–å¾ªç¯ç®¡ç†å™¨æµ‹è¯•\n")
    
    config = EvolutionConfig(
        iteration_name="test_evo_v1",
        rl_timesteps=1000,
        n_trajectories=50,
        peft_epochs=1
    )
    
    manager = EvolutionManager(config)
    await manager.run_loop()
    
    print("\n=== æŠ¥å‘Š ===")
    print(manager.get_report())


if __name__ == "__main__":
    asyncio.run(test_evolution())
